{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this hands-on lab we will perform few activities related to Convolutional Neural Networks (CNN), including their key operations, main layers and observe some results.\n",
    "\n",
    "To perform those activities it is important to address some requirements beforehand:\n",
    "\n",
    "1) deploy one AWS EC2 instance (P2.8x type) to be used as sandbox (it could be destroyed after the lab execution)\n",
    "\n",
    "2) After logging in the instance, run 'source activate tensorflow_p36'\n",
    "\n",
    "3) Create a directory as 'mkdir -p /models/ai-conference' and enter on it 'cd /models/ai-conference'\n",
    "\n",
    "4) Clone the github repository containing the labs 'git clone github link'\n",
    "\n",
    "This notebook includes the following activities:\n",
    "\n",
    "- basic CNN operations and exercising with kernels\n",
    "- building a sample CNN for image classifications using fruits dataset\n",
    "- train the neural network using the fruits dataset and evaluate its performance\n",
    "- report the performance metrics for that model, including precision, recall, f1score and support\n",
    "- performing transfer learning to speed up model creation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - CNN basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate that the required python modules are installed before starting\n",
    "\n",
    "!conda install -y seaborn Pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the python modules to be used across the notebook\n",
    "\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "# model configuration -- number of GPUs and training option (Yes or No)\n",
    "\n",
    "n_gpus = 8 # knob to make the model parallel or not\n",
    "train_model = False # knob to decide if the model will be trained or imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating few utility functions to assist with labs\n",
    "# convolve2D() helps running the same as a convolution layer on a convolutional neural network\n",
    "\n",
    "def convolve2D(img, kernel):\n",
    "    is_gray_scale = len(img.shape) == 2\n",
    "    \n",
    "    if is_gray_scale:\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "\n",
    "    img = pad_img(img, kernel)\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    new_img = []\n",
    "\n",
    "    for i in range(height - kernel.shape[0] + 1):\n",
    "        row = []\n",
    "        for j in range(width - kernel.shape[1] + 1):\n",
    "            channels = []\n",
    "            for k in range(img.shape[2]):\n",
    "                slice = img[i:i+kernel.shape[0], j:j+kernel.shape[1], k]\n",
    "                channels.append(np.expand_dims(np.sum(slice * kernel, keepdims=True), axis=0))\n",
    "            row.append(np.concatenate(channels, axis=2))\n",
    "        new_img.append(np.concatenate(row, axis=1))\n",
    "\n",
    "    res = np.maximum(np.concatenate(new_img, axis=0), 0).astype('uint8')\n",
    "\n",
    "    if is_gray_scale:\n",
    "        return res[:, :, 0]\n",
    "\n",
    "    return res\n",
    "\n",
    "# pad_img() helps convolve2D() to perform padding on a sample image\n",
    "\n",
    "def pad_img(img, kernel):\n",
    "    pad_height = (kernel.shape[0] - 1) // 2\n",
    "    pad_width = (kernel.shape[1] - 1) // 2\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        return np.pad(img, ((pad_height, pad_height),\n",
    "                            (pad_width, pad_width)), 'constant')\n",
    "    return np.pad(img, ((pad_height, pad_height),\n",
    "                        (pad_width, pad_width),\n",
    "                        (0, 0)), 'constant')\n",
    "\n",
    "# get_kernels() define few CNN kernels (filters) as sample to visualize how it does work\n",
    "\n",
    "def get_kernels():\n",
    "    kernels = []\n",
    "    kernels.append(('Identity',\n",
    "                     np.array([[0, 0, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])))\n",
    "    kernels.append(('Edge Detection1', \n",
    "                     np.array([[1, 0, -1],\n",
    "                               [0, 0, 0],\n",
    "                               [-1, 0, 1]])))\n",
    "    kernels.append(('Edge Detection2', \n",
    "                     np.array([[0, 1, 0],\n",
    "                               [1, -4, 1],\n",
    "                               [0, 1, 0]])))\n",
    "    kernels.append(('Edge Detection3', \n",
    "                     np.array([[-1, -1, -1],\n",
    "                               [-1, 8, -1],\n",
    "                               [-1, -1, -1]])))\n",
    "    kernels.append(('Sharpen', \n",
    "                     np.array([[0, -1, 0],\n",
    "                               [-1, 5, -1],\n",
    "                               [0, -1, 0]])))\n",
    "    kernels.append(('Box Blur', \n",
    "                     np.array([[1/9, 1/9, 1/9],\n",
    "                             [1/9, 1/9, 1/9],\n",
    "                             [1/9, 1/9, 1/9]])))\n",
    "    kernels.append(('Gaussian Blur', \n",
    "                     np.array([[1/16, 1/8, 1/16],\n",
    "                               [1/8, 1/4, 1/8],\n",
    "                               [1/16, 1/8, 1/16]])))\n",
    "    return kernels\n",
    "\n",
    "# plot_with_kernels() gets a sample image and show the result of sample kernels on it\n",
    "\n",
    "def plot_with_kernels(img):\n",
    "    kernels = get_kernels()\n",
    "    n_sub_plots = len(kernels)\n",
    "    \n",
    "    plt.figure('kernels', figsize=(20, 20))\n",
    "\n",
    "    for i, kernel in enumerate(kernels):\n",
    "        plt.subplot(n_sub_plots, 3, (i*3) + 1)\n",
    "        plt.text(0.5, 0.5, kernel[0],\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',\n",
    "                 fontsize=15)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(n_sub_plots, 3, (i * 3) + 2)\n",
    "        sns.heatmap(kernel[1], annot=True, cmap='YlGnBu')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(n_sub_plots, 3, (i+1) * 3)\n",
    "        \n",
    "        img_ = convolve2D(img, kernel[1])\n",
    "\n",
    "        if len(img_.shape) == 2:\n",
    "            plt.imshow(img_, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(img_)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# imshow() plots a image with matplotlib.plt\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# get_data_from_dir() helps importing image files from a given directory and importing them on variables as np arrays\n",
    "\n",
    "def get_data_from_dir(path, size=[100, 100]):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    labels_list = []\n",
    "\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        img_names = os.listdir(os.path.join(path, file))\n",
    "        \n",
    "        labels.append(np.ones(len(img_names)) * i)\n",
    "        labels_list.append(file)\n",
    "\n",
    "        for img_name in img_names:\n",
    "            with Image.open(os.path.join(path, file, img_name)) as img:\n",
    "                imgs.append(np.asarray(img.resize(size)))\n",
    "\n",
    "    imgs = np.asarray(imgs)\n",
    "    print('Found {} images belonging to {} different classes'.format(imgs.shape[0], len(labels_list)))\n",
    "\n",
    "    return imgs, np.hstack(labels), labels_list\n",
    "\n",
    "# train_test_split() performs a manual spliting of a given data in train and test datasets\n",
    "\n",
    "def train_test_split(X, y, val_split=0.2):\n",
    "    index = int(X.shape[0] * (1 - val_split))\n",
    "    return X[:index], y[:index], X[index:], y[index:]\n",
    "\n",
    "# shuffle() is used to shuffle datasets :-)\n",
    "\n",
    "def shuffle(X, y):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# one_hot() is used to convert categorical information in numerical values\n",
    "\n",
    "def one_hot(y):\n",
    "    return np.eye(int(np.max(y)) + 1)[y.astype('int')]\n",
    "\n",
    "# plot_some() simply prints few images from a dataset, including its labels\n",
    "\n",
    "def plot_some(X, y, y_hat=None, labels_list=None):\n",
    "    indices = np.random.randint(0, X.shape[0], size=10)\n",
    "    print(indices)\n",
    "\n",
    "    if labels_list is None:\n",
    "        labels_list = np.sort(np.unique(y))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(X[index])\n",
    "        plt.title('Y: {}    Y_hat: {}'. \\\n",
    "                  format(labels_list[int(y[index])], \n",
    "                         'N/A' if y_hat is None else labels_list[y_hat[index]]))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are importing a sample 128x128x3 image to exercise with CNN kernels\n",
    "\n",
    "img = np.array(Image.open('sample-128x128.jpg'))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick understanding of how a kernel convolves on a given image:\n",
    "![FilterUrl](https://mlnotebook.github.io/img/CNN/convSobel.gif \"CNN kernels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using plot_with_kernels() on the sample image to visualize how CNN kernels are defined and what is the result\n",
    "# of each kernel on the image\n",
    "\n",
    "plot_with_kernels(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Creating a CNN for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_data_from_dir() function to import the images from the dataset\n",
    "# then shuffles it and split it in train and test datasets\n",
    "\n",
    "if train_model is True:\n",
    "    X, y, labels_list = get_data_from_dir('Fruit-Images-Dataset/Training')\n",
    "    X, y = shuffle(X, y)\n",
    "    X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "    \n",
    "    # performs one_hot_encoding on all labels\n",
    "    y_train_hot = one_hot(y_train)\n",
    "    y_test_hot = one_hot(y_test)\n",
    "\n",
    "    print('Number of training Examples: {} \\nNumber of testing Examples {}'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_data_from_dir() function to import the images from the dataset\n",
    "# then shuffles it and use it as validation dataset\n",
    "\n",
    "X_val, y_val, labels_list = get_data_from_dir('Fruit-Images-Dataset/Val')\n",
    "X_val, y_val = shuffle(X_val, y_val)\n",
    "\n",
    "# performs one_hot_encoding on all labels\n",
    "y_val_hot = one_hot(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot few samples from the dataset, including their labels\n",
    "\n",
    "if train_model is True:\n",
    "    plot_some(X_train, y_train, labels_list=labels_list)\n",
    "else:\n",
    "    plot_some(X_val, y_val, labels_list=labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we gonna start the CNN training. The training happens as below:\n",
    "\n",
    "![ANNTraining](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/08/training_inference1.png \"CNN training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining few hyperparameters for the CNN\n",
    "\n",
    "input_shape = [100, 100, 3]\n",
    "n_classes = 93\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# start defining the CNN -- input, convolutions, maxpooling, flatten and FC layers\n",
    "\n",
    "if train_model is True:\n",
    "    \n",
    "    input = Input(input_shape)\n",
    "\n",
    "    model = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(input)\n",
    "    model = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "\n",
    "    model = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation='relu')(model)\n",
    "\n",
    "    preds = Dense(n_classes, activation='softmax')(model)\n",
    "    model = Model(inputs=input, outputs=preds)\n",
    "\n",
    "    # if we are using a multi-GPU EC2 instance, make the model multi-GPU aware\n",
    "\n",
    "    if n_gpus > 1:\n",
    "        final_model = multi_gpu_model(model, gpus=8)\n",
    "    else:\n",
    "        final_model = model\n",
    "\n",
    "    # compile the model\n",
    "\n",
    "    final_model.compile(optimizer='adam',\n",
    "                        loss='categorical_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "    # show a summary of the model -- including layers and tunable parameters\n",
    "    final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the CNN using the train dataset\n",
    "\n",
    "if train_model is True:\n",
    "    history = final_model.fit(X_train,\n",
    "                              y_train_hot,\n",
    "                              batch_size=batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model details\n",
    "\n",
    "if train_model is True:\n",
    "    \n",
    "    # save the model\n",
    "    model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "if train_model is True:\n",
    "    \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "if train_model is True:\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model accuracy\n",
    "\n",
    "if train_model is not True:\n",
    "\n",
    "    from keras.models import load_model\n",
    "    final_model = load_model('cnn_model.h5')\n",
    "    final_model.compile(optimizer='adam',\n",
    "                        loss='categorical_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "results = final_model.evaluate(X_val, y_val_hot)\n",
    "print('Loss on Validation set: {}  and Accuracy on Validation Set: {}'.format(results[0], results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the model precision, recall, f1score and support \n",
    "\n",
    "predictions = final_model.predict(X_val)\n",
    "report = classification_report(y_val_hot.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid memory and/or cpu usage issues, it is important to reset the Jupyter Notebook kernel.\n",
    "\n",
    "This task can be performed as:\n",
    "\n",
    "- go to the Jupyter notebook menu (up there)\n",
    "- click on 'Kernel'\n",
    "- click on 'Restart'\n",
    "- wait for the kernel to restart\n",
    "\n",
    "Once the restart procedure is finished, go ahead on the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use VGG16 pre-trained model present on Keras framework\n",
    "# import the pre-trained model\n",
    "\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained weights and model definition, including the FC layer\n",
    "# this pre-trained model is configured to use 224x224x3 images\n",
    "\n",
    "vgg_model = applications.VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model configuration\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules important to run this drill\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('sample-224x224.jpg', target_size=(224, 224))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the image to be used with the model\n",
    "\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "\n",
    "prediction = vgg_model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the probabilities to class labels\n",
    "\n",
    "label = decode_predictions(prediction)\n",
    "\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "\n",
    "label = label[0][0]\n",
    "\n",
    "# print the classification\n",
    "\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning things up\n",
    "\n",
    "Not much actions must be taken to clean the environment used on this lab.\n",
    "\n",
    "As a new EC2 instance was created for this purpose, simply terminate the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
